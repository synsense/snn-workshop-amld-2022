{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c6f220d-c625-40d9-90cc-4bf94b5b51b0",
   "metadata": {
    "id": "8c6f220d-c625-40d9-90cc-4bf94b5b51b0"
   },
   "source": [
    "# Dance recognition training - full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oKkZE2mBvULV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKkZE2mBvULV",
    "outputId": "bf01c0ea-6619-4e4c-bd56-4cbffae3a372"
   },
   "outputs": [],
   "source": [
    "### --- Download dataset\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_path = Path(\"/content\") / \"body-postures\"\n",
    "\n",
    "if not dataset_path.exists():\n",
    "  !wget https://www.dropbox.com/s/b9gfafnh6aesrsu/body-postures-dataset.bin\n",
    "  # alternative mirror: https://lenzgregor.com/nextcloud/s/tbamCq9Eo95qfLc/download/body-postures-dataset.bin\n",
    "  !mv body-postures-dataset.bin body-postures-dataset.tar.gz\n",
    "  !tar -xzf body-postures-dataset.tar.gz\n",
    "  !cd body-postures-dataset; python -m pip install .\n",
    "\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b430d407-1cf2-44d8-a40c-a0a18e178489",
   "metadata": {
    "id": "b430d407-1cf2-44d8-a40c-a0a18e178489"
   },
   "outputs": [],
   "source": [
    "### --- Imports\n",
    "from typing import Optional\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torch import nn\n",
    "\n",
    "# Dataset\n",
    "from body_postures import BodyPostureFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e91720-80f1-4126-8593-4630c5b7b5d3",
   "metadata": {
    "id": "a5e91720-80f1-4126-8593-4630c5b7b5d3"
   },
   "source": [
    "### Settings and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5f2504-9edf-42ff-aca6-ec5018bbd53b",
   "metadata": {
    "id": "af5f2504-9edf-42ff-aca6-ec5018bbd53b"
   },
   "outputs": [],
   "source": [
    "n_classes = 7\n",
    "batch_size = 256\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e34c81-5d62-41e6-bba8-c4ba432db4a0",
   "metadata": {
    "id": "25e34c81-5d62-41e6-bba8-c4ba432db4a0"
   },
   "source": [
    "## Data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c86a1-e473-449a-b189-76a88a95769a",
   "metadata": {
    "id": "bb4c86a1-e473-449a-b189-76a88a95769a"
   },
   "outputs": [],
   "source": [
    "frame_dataset_training = BodyPostureFrames(\n",
    "    cache_path='cache/frames_training',\n",
    "    event_count=3000,\n",
    "    reset_cache=True,\n",
    "    train=True,\n",
    "    hot_pixel_filter_freq=60\n",
    ")\n",
    "print(len(frame_dataset_training))\n",
    "frame_dataset_validation = BodyPostureFrames(\n",
    "    cache_path='cache/frames_val',\n",
    "    event_count=3000,\n",
    "    reset_cache=True,\n",
    "    train=False,\n",
    "    hot_pixel_filter_freq=60\n",
    ")\n",
    "print(len(frame_dataset_validation))\n",
    "train_loader = torch.utils.data.DataLoader(frame_dataset_training, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(frame_dataset_validation, batch_size=batch_size)\n",
    "\n",
    "classes = {\n",
    "    0: \"background\",\n",
    "    1: \"clap\",\n",
    "    2: \"mj\",\n",
    "    3: \"salive\",\n",
    "    4: \"star\",\n",
    "    5: \"wave\",\n",
    "    6: \"other\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e251d3-a334-4a84-85d2-e4cafa79e8ec",
   "metadata": {
    "id": "31e251d3-a334-4a84-85d2-e4cafa79e8ec"
   },
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa05cdb9-08ac-4cab-b3d0-0c9c2d705b73",
   "metadata": {
    "id": "fa05cdb9-08ac-4cab-b3d0-0c9c2d705b73"
   },
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        # The actual network\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(2, 16, kernel_size=(3, 3), stride=2, padding=1, bias=False),  # 16, 64, 64\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2)),  # 16, 32, 32\n",
    "            nn.Dropout2d(0.1),\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 3), stride=2, padding=1, bias=False),  # 32, 16, 16\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2)),  # 32, 8, 8\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(32, 32, kernel_size=(3, 3), stride=1, padding=1, bias=False),  # 64, 4, 4\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2)),  # 64, 2, 2\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout2d(0.5),\n",
    "            \n",
    "            nn.Linear(32*4*4, n_classes, bias=False),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Reshape data\n",
    "        x = torch.as_tensor(x, dtype=torch.float32).squeeze(1)\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00852d7d-324e-4175-bf0f-0159eefe9206",
   "metadata": {
    "id": "00852d7d-324e-4175-bf0f-0159eefe9206"
   },
   "outputs": [],
   "source": [
    "ann = ANN(n_classes)\n",
    "\n",
    "## -- Prepare training\n",
    "# - Loss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# - Optimizer\n",
    "optimizer = torch.optim.Adam(ann.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# - Confusion matrix\n",
    "confusion_matrix = torchmetrics.ConfusionMatrix(num_classes=n_classes)\n",
    "\n",
    "# - Training loop\n",
    "def train(num_epochs: int=100, validate_every: Optional[None]=5):\n",
    "    \n",
    "    # Track losses\n",
    "    training_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracy = []\n",
    "    \n",
    "    pbar_epoch = tqdm(range(num_epochs), desc=\"Epochs\")\n",
    "    pbar_batches_tr = tqdm(train_loader, desc=\"Batches training\")\n",
    "    pbar_batches_val = tqdm(val_loader, desc=\"Batches validation\")\n",
    "    for epoch in pbar_epoch:\n",
    "        losses = []\n",
    "        for data, labels in pbar_batches_tr:\n",
    "            # Forward pass\n",
    "            logits = ann(data)\n",
    "            # Loss for current batch\n",
    "            loss = criterion(logits, labels)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = loss.item()\n",
    "            losses.append(loss)\n",
    "            pbar_batches_tr.set_postfix(loss=loss)\n",
    "        \n",
    "        epoch_loss = sum(losses) / len(losses)\n",
    "        training_losses.append(epoch_loss)\n",
    "        pbar_batches_tr.set_postfix(loss=epoch_loss)\n",
    "        \n",
    "        # Validation\n",
    "        if validate_every is not None and epoch % validate_every == 0:\n",
    "            with torch.no_grad():\n",
    "                val_data = []\n",
    "                losses = []\n",
    "                for data, labels in pbar_batches_val:\n",
    "                    logits = ann(data)\n",
    "                    # Loss\n",
    "                    val_loss = criterion(logits, labels)\n",
    "                    losses.append(val_loss)\n",
    "                    # Collect outputs and labels\n",
    "                    predictions = torch.max(logits, dim=1)[1]\n",
    "                    val_data.append((predictions, labels))\n",
    "                \n",
    "                val_losses.append(sum(losses) / len(losses))\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                confusion_list = [confusion_matrix(pred, label) for pred, label in val_data]\n",
    "                confusion = torch.stack(confusion_list).sum(0)\n",
    "                val_accuracy = confusion.trace() / confusion.sum()\n",
    "                \n",
    "                pbar_batches_val.set_postfix(loss=val_loss, accuracy=val_accuracy)\n",
    "                \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421cce6b-a74c-42bb-869a-fae54e9b6fc0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392,
     "referenced_widgets": [
      "34ec44d4c61a426cbb58c46eafdfa54f",
      "f97d0e0f2f6c42ca88ed5f6912d07f08",
      "71ee0048b40144769734a168a9cd9527",
      "b1139521dfc54c2fb95e317a95e16206",
      "8b0a8690908d4a57a623db9b6a420719",
      "22a74ba0c3ea4c84a9e5ffc20640283a",
      "b5dde78654ce4b2294f1365c32f43d3a",
      "dfeb9d5d0e4e4cf280b196b0f9df7d99",
      "0c43362a2925445283d43ea023c16ab5",
      "db03d2a8d49d4d029f31679e838a7828",
      "5333267de2ee42fcbfb4f3bea76e0735",
      "b2f961bfaf2f4304998484f2969a71fa",
      "6b713d503c3149b889b156625ce66264",
      "493f815279144ab5ab2bf5933497a178",
      "532aa111d94d44dfb47203067588b035",
      "b6ba53b4ea4f4a23b75e88089e313589",
      "4ccdb35d7930429387a2f7bf591af862",
      "626df4166e084f28bf3c12544480a66e",
      "2e191f02c3ef41ceaff438dc2e4a4b35",
      "561d94ae41dc4e03a85fb519eafe8867",
      "d38b39ea33e84c118aefe1932747c373",
      "f448cf3cfa5149ef9291532bbe1bc683",
      "d87606018e6c4f31bee0ed34ac015dd8",
      "5dca22c703a54a7d9f6c8dca37853913",
      "b870e31901ae4d39a3ebf4b4141b4323",
      "6e7c5d47cdc1401dbff71cedd2d48fd4",
      "c3ea77f7c55e4f878e33eadf059d04a9",
      "8cc31d3001224fe1b0a7025ae3efefe3",
      "c777a43b1af64c60989d0afb9c362347",
      "109fd932e38f4f8d9b3ec852ac7eb7be",
      "503c8856ea3a4713a6f01dd5bdd15906",
      "a9f6eb65871345298c01a5ca03309ff4",
      "e1fabc75bbc244719879dd5b23f1b7af"
     ]
    },
    "id": "421cce6b-a74c-42bb-869a-fae54e9b6fc0",
    "outputId": "3ca51e40-9c28-4cc2-e5a6-583c499347a9"
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd619b0-bbbc-4f94-ac0c-b5718dbd0024",
   "metadata": {
    "id": "dbd619b0-bbbc-4f94-ac0c-b5718dbd0024"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "train_full.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
