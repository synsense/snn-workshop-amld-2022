{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/synsense/snn-workshop-amld-2022/blob/master/1.%20Introduction%20to%20SNNs/Intro_workbook.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"image.cmap\"] = 'Greys'\n",
    "\n",
    "# Utility function\n",
    "def setFig():\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Lets create and visualize such data\n",
    "n_input_channels = ...\n",
    "n_time_samples = ...\n",
    "\n",
    "# Our sample data stream (time, channel)\n",
    "data_stream = ...\n",
    "\n",
    "# Display data\n",
    "setFig()\n",
    "plt.plot(data_stream);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Networks\n",
    "\n",
    "Lets do a quick recap of ANNs.\n",
    "\n",
    "The standard artificial neuron model used most commonly in ANNs and DNNs is a simple equation\n",
    "\n",
    "$\\vec{y} = \\Theta(W.\\vec{x} + b)$\n",
    "\n",
    "where $\\Theta$ is typically a non linear activation function such as a *ReLU*, *sigmoid* or *hyperbolic tangent* function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div>\n",
    "    <img src=\"AN-neuron.png\" width=30%/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to compute the weighted sum of an input data stream\n",
    "#   Arguments:\n",
    "#     x - vector of inputs (Nbatches, Nsamples, Nin,)\n",
    "#     W - weight matrix (Nin, Nout)\n",
    "#     b - Bias input vector (Nout,)\n",
    "def forward_ann(x, W, b):\n",
    "    # - Compute x matmul W\n",
    "    #   Add bias vector\n",
    "    return ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Let us generate a random weight matrix\n",
    "W = ...\n",
    "b = ... # Some bias value\n",
    "\n",
    "# Compute the output\n",
    "y = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "setFig()\n",
    "plt.plot(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU\n",
    "\n",
    "ReLU: Rectified linear unit adds a nonlinearlity to a neuron's activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compute and return ReLU of result (Hint: `torch.clamp`)\n",
    "out = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "setFig()\n",
    "plt.plot(out);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The output is as uncorrelated in time as the input!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed forward networks\n",
    "\n",
    "Several such (weights + ReLU) layers put together form the basis of what we we refer to as feed forward neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent networks\n",
    "\n",
    "When we want to introduce memory into a model, we use recurrent neural networks, that are a slight modification to feed forward models.\n",
    "\n",
    "$\\vec{y}(t) = \\Theta(\\vec{y}(t-1) + W.\\vec{x} + b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div>\n",
    "    <img src=\"AN-neuron-rec.png\" width=30%/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define a forward method for a recurrent neuron model\n",
    "def forward_rnn(x, W, b):\n",
    "    time, n_input = x.shape\n",
    "    y = []\n",
    "    y_last = 0\n",
    "    for t in range(time):\n",
    "        # Update internal state\n",
    "        v_mem = ...\n",
    "        # Compute the activation\n",
    "        y_last = ...\n",
    "        # Record the activation\n",
    "        ...\n",
    "    return torch.concat(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "setFig()\n",
    "plt.plot(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here you see that the neuron's output integrates its inputs from the past. The information that it retains can be used to perform interesting computations, especially when a population of neurons interact in the case of RNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spiking Neural Networks\n",
    "\n",
    "Spiking neurons improve upon this notion of recurrent neurons by making the output binary and sparse.\n",
    "\n",
    "They do so by replacing the activation function (ReLU) with a spike function.\n",
    "\n",
    "If the internal state is above a threshold $\\theta$, the neuron produces a binary event on the output. We'll use a Heaviside function for that.\n",
    "\n",
    "$$y = H(v, \\theta) = v > \\theta$$\n",
    "\n",
    "When a neuron sends an output, we reset $v$ by subtracting the threshold:\n",
    "\n",
    "$$v = v - y * \\theta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate and Fire Neuron\n",
    "\n",
    "So putting all these things together, the dynamics of an Integrate and Fire Neuron can be defined as follows:\n",
    "\n",
    "$$\\vec{v}(t) = \\vec{v}(t-1) + W.\\vec{x} + b - \\vec{y}\\theta$$\n",
    "\n",
    "$$y = H(v, \\theta) = v > \\theta$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div>\n",
    "    <img src=\"iaf.png\" width=30%/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define a forward method for a spiking neuron model\n",
    "def forward_snn(x, W, b, threshold=10.0):\n",
    "    # Initialize variables\n",
    "    time, n_input = x.shape\n",
    "    y = []\n",
    "    v_mem = []\n",
    "    v_mem_last = 0\n",
    "    y_last = 0\n",
    "    for t in range(time):\n",
    "        # State update\n",
    "        v_mem_last = ...\n",
    "        # Activation\n",
    "        y_last = ...\n",
    "        # record output\n",
    "        ...\n",
    "        # record state\n",
    "        ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Generate input spikes\n",
    "spike_stream = ...\n",
    "\n",
    "# Perform a forward pass\n",
    "y, v_mem = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Input and output visualization\n",
    "\n",
    "# Plot input\n",
    "setFig()\n",
    "...\n",
    "\n",
    "# Plot internal state\n",
    "setFig()\n",
    "...\n",
    "\n",
    "# Plot output\n",
    "setFig()\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Key take aways\n",
    "\n",
    "1. Neurons hold **memory of past data**.\n",
    "2. The input data is **binary**. This means computation is **much cheaper** than floating point operations in terms of **power**.\n",
    "3. The input and output are **sparse**. This means you only need to perform a **fraction of the operations** needed for an fully connected RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training strategies\n",
    "\n",
    "We have seen how a spiking neuron works. How do you make them do interesting tasks?\n",
    "\n",
    "In the sessions to follow, you will see how to get large number of spiking neurons to do interesting real-world tasks.\n",
    "You will see how they work real-time on neuromorphic hardware.\n",
    "\n",
    "Most importantly, you will do this all by yourself (with our help!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}