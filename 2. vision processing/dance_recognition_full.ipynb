{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c6f220d-c625-40d9-90cc-4bf94b5b51b0",
   "metadata": {
    "id": "8c6f220d-c625-40d9-90cc-4bf94b5b51b0"
   },
   "source": [
    "# Dance recognition - complete\n",
    "\n",
    "## Setup\n",
    "First we download the dataset and install missing packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oKkZE2mBvULV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKkZE2mBvULV",
    "outputId": "703ae2c5-0a6f-4b12-fc9d-63c9646c9220"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# - Download of dataset\n",
    "dataset_path = Path(\"/content\") / \"body-postures-dataset\"\n",
    "\n",
    "if not dataset_path.exists():\n",
    "  !wget -q --show-progress https://www.dropbox.com/s/b9gfafnh6aesrsu/body-postures-dataset.bin\n",
    "  # alternative mirror: https://lenzgregor.com/nextcloud/s/tbamCq9Eo95qfLc/download/body-postures-dataset.bin\n",
    "  !mv body-postures-dataset.bin body-postures-dataset.tar.gz\n",
    "  !tar -xzf body-postures-dataset.tar.gz\n",
    "\n",
    "# - Install dataset as package\n",
    "!pip install ./body-postures-dataset --quiet\n",
    "\n",
    "# - Install torchmetrics\n",
    "!pip install torchmetrics --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b430d407-1cf2-44d8-a40c-a0a18e178489",
   "metadata": {
    "id": "b430d407-1cf2-44d8-a40c-a0a18e178489"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "from body_postures import BodyPostureFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6WVpUOqzzib3",
   "metadata": {
    "id": "6WVpUOqzzib3"
   },
   "source": [
    "## Data inspection\n",
    "\n",
    "The original data consits of a continuous stream of asynchronous events - each with its own time stamp. On an asynchronous neuromorhpic processor, the dynamics of the network are continuous in time and are directly linked to the timings of the input events.\n",
    "\n",
    "However, we are going to train our model on a CPU or GPU, which are synchronous (clocked) compute architectures. We therefore need to represent the envents in discretized time. We are going to use two different ways of arranging the events, depending on the type of neural network into which we are feeding the data.\n",
    "\n",
    "### Frame representation\n",
    "\n",
    "For artificial neural networks (ANNs), we will split the data stream of each recording into segments, each with the same, pre-defined number of events. \n",
    "\n",
    "In the individual segments we count the number of events for each pixel and channel. This way we eliminate the time dimension, such that each segment now has become a static frame. The frames could be compared to grey-scale images, with the brightness corresponding to the event count. Nothe that different to the frames of a conventional video camera, each frame here generally represents a different amount of time.\n",
    "\n",
    "The frame based representation is provided by `BodyPostureFrames`, which is a subclass of a PyTorch dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nhdPEU8-YTuD",
   "metadata": {
    "id": "nhdPEU8-YTuD"
   },
   "outputs": [],
   "source": [
    "?BodyPostureFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F8qJzAZG_7kT",
   "metadata": {
    "id": "F8qJzAZG_7kT"
   },
   "source": [
    "We will use this class to provide the input for training an ANN. Let's generate a training and and a test set. It might take a few seconds to convert the events into frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c86a1-e473-449a-b189-76a88a95769a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bb4c86a1-e473-449a-b189-76a88a95769a",
    "outputId": "dd7a46ae-9131-4a3f-d985-76ed649dc5c6"
   },
   "outputs": [],
   "source": [
    "# The number of events per frame\n",
    "event_count = 3000\n",
    "\n",
    "# Ignore pixels where the firing frequency exceeds a given value\n",
    "hot_pixel_filter_freq = 60\n",
    "\n",
    "# Training dataset\n",
    "frame_dataset_training = BodyPostureFrames(\n",
    "    data_path=dataset_path / \"data\" / \"train\",\n",
    "    event_count=event_count,\n",
    "    hot_pixel_filter_freq=hot_pixel_filter_freq,\n",
    "    metadata_path=f'metadata/frames/train/{event_count}events_{hot_pixel_filter_freq}filter',\n",
    ")\n",
    "\n",
    "# Validation dataset\n",
    "frame_dataset_validation = BodyPostureFrames(\n",
    "    data_path=dataset_path / \"data\" / \"test\",\n",
    "    event_count=event_count,\n",
    "    hot_pixel_filter_freq=hot_pixel_filter_freq,\n",
    "    metadata_path=f'metadata/frames/test/{event_count}events_{hot_pixel_filter_freq}filter',\n",
    ")\n",
    "\n",
    "classes = frame_dataset_training.classes\n",
    "shape = frame_dataset_training.shape\n",
    "n_classes = len(classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JJtpYK8fAgSE",
   "metadata": {
    "id": "JJtpYK8fAgSE"
   },
   "source": [
    "It can happen that some pixels of our sensor just produce random events at a high rate. We want to ignore these. With the `hot_pixel_filter_freq` argument we set an upper limit for which event rate we consider reasonable. Any pixel emitting events at a higher rate is probably just generating noise and will be ignored. \n",
    "\n",
    "For efficient data loading we do the conversion of events into frames only once and then buffer the data on disk, under the `metadata_path`.\n",
    "\n",
    "Let's have a closer look at our data! For this we pick some frame from our training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W_QtjT3DCBcB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "W_QtjT3DCBcB",
    "outputId": "4803d419-f8af-4891-c710-2c38407f4c69"
   },
   "outputs": [],
   "source": [
    "sample_index = 42\n",
    "frame, label = frame_dataset_training[sample_index]\n",
    "\n",
    "print(\"Frame data type:\", type(frame))\n",
    "print(\"Frame shape:\", frame.shape)\n",
    "print(\"Frame sum:\", frame.sum())\n",
    "print(\"Max. number events at single pixel:\", frame.max())\n",
    "plt.imshow(frame[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-_SGkLd7DEME",
   "metadata": {
    "id": "-_SGkLd7DEME"
   },
   "source": [
    "The frame is a numpy array of shape (1, 128, 128). The first dimension is the number of channels, which in this case is 1. The other two dimensions correspond to the image size. We see that our input has a resolution of 128x128.\n",
    "\n",
    "We also note that the total number of events in the frame is 3000, which is what we have previously defined with the `event_count` argument.\n",
    "\n",
    "When plotting the frame, brighter areas correspond to regions with a higher number of events. Because events are generated from intensity changes, those are the regions where something is happening. Any static background becomes invisible and we only see the shape of the person moving in front of the sensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lTZugl6eGLq-",
   "metadata": {
    "id": "lTZugl6eGLq-"
   },
   "source": [
    "### Ground truth\n",
    "\n",
    "Every sample in the dataset comes with a label that enumerates the correct class. The `classes` dict maps the names of the classes to their integer labels. There are five poses (\"clap\", \"mj\", \"salive\", \"star\" and \"wave\") as well as a \"background\" class for recordings without any person and \"other\", when a person is not performing any known move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6g9mvcyQEjBx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6g9mvcyQEjBx",
    "outputId": "a244f26e-014c-4947-e6da-0a87f14c4c46"
   },
   "outputs": [],
   "source": [
    "print(\"Label:\", label)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9013829-f2fd-4f0f-a8e3-c561f634064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Dict to map labels to classes\n",
    "lbl2clss = {lbl: clss for clss, lbl in classes.items()}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "screen = ax.imshow(frame_dataset_training[0][0][0])\n",
    "\n",
    "def update_plot(sample):\n",
    "    frame, label = sample\n",
    "    screen.set_data(frame[0])\n",
    "    ax.set_title(f\"Label: {label} (`{lbl2clss[label]}`)\")\n",
    "    \n",
    "anim = FuncAnimation(fig, update_plot, frames=frame_dataset_training, interval=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e34c81-5d62-41e6-bba8-c4ba432db4a0",
   "metadata": {
    "id": "25e34c81-5d62-41e6-bba8-c4ba432db4a0"
   },
   "source": [
    "### Data balancing\n",
    "\n",
    "The dataset is imbalanced. Let's look at training and testing set distribution and rectify the training set by using weighted random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u-TeJyex-jHU",
   "metadata": {
    "id": "u-TeJyex-jHU"
   },
   "outputs": [],
   "source": [
    "def get_weight_sampler(dataset):\n",
    "  targets = []\n",
    "  for data, target in iter(dataset):\n",
    "    targets.append(target)\n",
    "  targets = np.array(targets)\n",
    "\n",
    "  count = np.bincount(targets)\n",
    "  frac = count / np.sum(count)\n",
    "  sample_weights_per_class = dict(zip(range(n_classes), 1 / frac / count.sum()))\n",
    "\n",
    "  sample_weights = [sample_weights_per_class[target] for target in targets]\n",
    "  sampler = WeightedRandomSampler(sample_weights, len(dataset), replacement=True)\n",
    "  return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2EHJFbrQ00G4",
   "metadata": {
    "id": "2EHJFbrQ00G4"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_loader = DataLoader(\n",
    "    dataset=frame_dataset_training, \n",
    "    batch_size=batch_size,\n",
    "    sampler=get_weight_sampler(frame_dataset_training)\n",
    "    )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=frame_dataset_validation,\n",
    "    batch_size=batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EJ3jS12g_Uvp",
   "metadata": {
    "id": "EJ3jS12g_Uvp"
   },
   "outputs": [],
   "source": [
    "def plot_sample_dist(dataloader):\n",
    "  resampled_targets = []\n",
    "  for data, target in iter(dataloader):\n",
    "    resampled_targets.append(target)\n",
    "  resampled_targets = torch.cat(resampled_targets).numpy()\n",
    "\n",
    "  plt.bar(classes.keys(), np.bincount(resampled_targets))\n",
    "  plt.ylabel(\"Number of samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0F5HnnSuAjZZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "0F5HnnSuAjZZ",
    "outputId": "3e039a20-aeed-4c76-933a-79266dd8fb20"
   },
   "outputs": [],
   "source": [
    "plot_sample_dist(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TkFhBEcR_icT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "TkFhBEcR_icT",
    "outputId": "52898e2c-45a0-4739-db7f-e1702f69ca97"
   },
   "outputs": [],
   "source": [
    "plot_sample_dist(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e91720-80f1-4126-8593-4630c5b7b5d3",
   "metadata": {
    "id": "a5e91720-80f1-4126-8593-4630c5b7b5d3"
   },
   "source": [
    "### Settings and hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SypRWbGqF6FF",
   "metadata": {
    "id": "SypRWbGqF6FF"
   },
   "source": [
    "You can try out different learning rates and weight decays here, but the providedd defaults should yield reasonable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5f2504-9edf-42ff-aca6-ec5018bbd53b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af5f2504-9edf-42ff-aca6-ec5018bbd53b",
    "outputId": "ac46dd1e-24fd-478f-d6aa-2895f46edac1"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "weight_decay = 0\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e251d3-a334-4a84-85d2-e4cafa79e8ec",
   "metadata": {
    "id": "31e251d3-a334-4a84-85d2-e4cafa79e8ec"
   },
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BKUH2XrsGX1c",
   "metadata": {
    "id": "BKUH2XrsGX1c"
   },
   "source": [
    "We suggest to use the following model architecture. Remember, the input shape of each frame is (1, 128, 128)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa05cdb9-08ac-4cab-b3d0-0c9c2d705b73",
   "metadata": {
    "id": "fa05cdb9-08ac-4cab-b3d0-0c9c2d705b73"
   },
   "outputs": [],
   "source": [
    "class ANN(nn.Sequential):\n",
    "    def __init__(self, n_classes=10):\n",
    "        super().__init__(\n",
    "            nn.Conv2d(1, 16, kernel_size=(3, 3), stride=2, padding=1, bias=False),  # 16, 64, 64\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2)),  # 16, 32, 32\n",
    "            nn.Dropout2d(0.1),\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 3), stride=2, padding=1, bias=False),  # 32, 16, 16\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2)),  # 32, 8, 8\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(32, 32, kernel_size=(3, 3), stride=1, padding=1, bias=False),  # 64, 4, 4\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2)),  # 64, 2, 2\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout2d(0.5),\n",
    "            \n",
    "            nn.Linear(32*4*4, n_classes, bias=False),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00852d7d-324e-4175-bf0f-0159eefe9206",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "0313e95d3bff4fa0a5e85982602447f0",
      "dce0d5e6f6e54860bcf76cdc238ff998",
      "9e5eef22260240f484ef2ddfe4c6b7be",
      "20214c91cc2b40178a9bf0a9b15f176d",
      "944187b000714836b04a3c2c48a6538d",
      "f6402d7a361843d19954eb0f1edbbbdd",
      "e8d60af9b26a46088e166fadf01a5b6b",
      "b1f09e7b1e0f41f3bce2d10ac56e59f0",
      "8f32be1d210b4025a2b3248bf2ba1438",
      "543f3cea0c0441dfbf2b488ec2fecf6b",
      "b674dc3bce7246dcbb6aefd051a7613e"
     ]
    },
    "id": "00852d7d-324e-4175-bf0f-0159eefe9206",
    "outputId": "a2eeed39-1cfd-4dd3-b7c4-3f5f8d322ce4"
   },
   "outputs": [],
   "source": [
    "ann = ANN(n_classes).to(device)\n",
    "\n",
    "# - Loss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# - Optimizer\n",
    "optimizer = torch.optim.Adam(ann.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# - Confusion matrix\n",
    "confusion_matrix = torchmetrics.ConfusionMatrix(num_classes=n_classes)\n",
    "\n",
    "num_epochs = 10\n",
    "validate_every = 5\n",
    "\n",
    "# We use augmentation because we're oversampling underrepresented classes. \n",
    "augmentation = torchvision.transforms.RandomAffine(degrees=10, translate=[0.1, 0.1])\n",
    "\n",
    "# Track losses\n",
    "training_losses = []\n",
    "val_losses = []\n",
    "val_accuracy = 0\n",
    "val_loss = 0\n",
    "\n",
    "pbar_epoch = tqdm(range(num_epochs), desc=\"Epochs\")\n",
    "for epoch in pbar_epoch:\n",
    "    batch_loss = []\n",
    "    for data, labels in iter(train_loader):\n",
    "        # Forward pass\n",
    "        data = data.to(device)\n",
    "        data = augmentation(data)\n",
    "        logits = ann(data)\n",
    "        # Loss for current batch\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.append(loss.item())\n",
    "\n",
    "    train_loss = sum(batch_loss) / len(batch_loss)\n",
    "    training_losses.append(train_loss)\n",
    "    pbar_epoch.set_postfix(train_loss=train_loss, val_loss=val_loss, val_acc=val_accuracy)\n",
    "    \n",
    "    # Validation\n",
    "    if validate_every is not None and (epoch + 1) % validate_every == 0:\n",
    "        with torch.no_grad():\n",
    "            val_data = []\n",
    "            batch_loss = []\n",
    "            for data, labels in iter(test_loader):\n",
    "                logits = ann(data.to(device))\n",
    "                # Loss\n",
    "                loss = criterion(logits, labels.to(device))\n",
    "                batch_loss.append(loss.item())\n",
    "                # Collect outputs and labels\n",
    "                predictions = torch.max(logits, dim=1)[1]\n",
    "                val_data.append((predictions.detach().cpu(), labels.detach().cpu()))\n",
    "            \n",
    "            val_loss = sum(batch_loss) / len(batch_loss)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            confusion_list = [confusion_matrix(pred, label) for pred, label in val_data]\n",
    "            confusion = torch.stack(confusion_list).sum(0)\n",
    "            val_accuracy = (confusion.trace() / confusion.sum()).item()\n",
    "            \n",
    "        pbar_epoch.set_postfix(train_loss=train_loss, val_loss=val_loss, val_acc=val_accuracy)\n",
    "            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VTNnYWTph-NT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "VTNnYWTph-NT",
    "outputId": "acee55fb-b796-4d1b-dc50-76434c066d04"
   },
   "outputs": [],
   "source": [
    "plt.plot(training_losses)\n",
    "plt.plot(range(0, len(training_losses), validate_every), val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LWRzKLNyMpLr",
   "metadata": {
    "id": "LWRzKLNyMpLr"
   },
   "source": [
    "# Convert ANN to SNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f5cdd2-13a5-4cfc-80a0-dc4b9c2d7369",
   "metadata": {},
   "source": [
    "For working with SNNs we will use our in-house library Sinabs. You can find out more about here: https://sinabs.readthedocs.io/en/develop/index.html ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dU5jOTFrKYIe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dU5jOTFrKYIe",
    "outputId": "33cc5f9b-7f66-4695-a9e8-9a94ce382df1"
   },
   "outputs": [],
   "source": [
    "ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IQg6U1y9KxcA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQg6U1y9KxcA",
    "outputId": "d8ba0711-5b48-4a67-94a4-10fc7ae0bda9"
   },
   "outputs": [],
   "source": [
    "sinabs_path = Path(\"/content\") / \"sinabs\"\n",
    "\n",
    "if not sinabs_path.exists():\n",
    "  !git clone https://github.com/synsense/sinabs.git\n",
    "  !cd sinabs; pip install . --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ctFILsxqMO-v",
   "metadata": {
    "id": "ctFILsxqMO-v"
   },
   "outputs": [],
   "source": [
    "import sinabs\n",
    "import copy\n",
    "\n",
    "ann_copy = copy.deepcopy(ann)\n",
    "\n",
    "spike_layers = [name for name, child in ann_copy.cpu().named_children() if isinstance(child, nn.ReLU)]\n",
    "param_layers = [name for name, child in ann_copy.cpu().named_children() if isinstance(child, (nn.Conv2d, nn.Linear))]\n",
    "data = next(iter(train_loader))[0]\n",
    "\n",
    "sinabs.utils.normalize_weights(ann_copy, data, output_layers=spike_layers, param_layers=param_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZJduQXLFTlqW",
   "metadata": {
    "id": "ZJduQXLFTlqW"
   },
   "source": [
    "We can scale the weights of the first layer to help the network with decision making. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FBvmnIJvPQg-",
   "metadata": {
    "id": "FBvmnIJvPQg-"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  ann_copy[0].weight *= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KecYTlVOz_4K",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KecYTlVOz_4K",
    "outputId": "73ee6296-b3d1-4e2b-a2dd-1ea814254fed"
   },
   "outputs": [],
   "source": [
    "snn = sinabs.from_torch.from_model(ann_copy, input_shape=(1, 128, 128), add_spiking_output=True)\n",
    "snn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fHdIM9xR2qZJ",
   "metadata": {
    "id": "fHdIM9xR2qZJ"
   },
   "outputs": [],
   "source": [
    "torch.save(snn, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y0WjZyYY2_ET",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y0WjZyYY2_ET",
    "outputId": "b995b76b-819a-4026-8e84-ccb81073565b"
   },
   "outputs": [],
   "source": [
    "# Load previously saved model\n",
    "\n",
    "snn = torch.load('model.pth')\n",
    "print(\"Loaded saved model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X_VHbLVpdtr8",
   "metadata": {
    "id": "X_VHbLVpdtr8"
   },
   "source": [
    "## Evaluate converted SNN on event data\n",
    "\n",
    "### Event Representation\n",
    "\n",
    "For spiking neural networks (SNNs) we use a similar representation to the frames we used for the ANN. However, here we want to maintain a notion of time, to mimick the neuron dynamics on the neuromorphic processor. We therefore arrange our events in time along a grid of very short intervals, corresponding to a simulation time step. This time step should be chosen small enough such that the neuron dynamics are well approximated. On the other hand, choosing it too short will slow down our simulations.\n",
    "\n",
    "Data in this format will be porovided to us by the class `BodyPostureEvents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fElIESQWdjnd",
   "metadata": {
    "id": "fElIESQWdjnd"
   },
   "outputs": [],
   "source": [
    "from body_postures import BodyPostureEvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DAL0yf24ZRa0",
   "metadata": {
    "id": "DAL0yf24ZRa0"
   },
   "outputs": [],
   "source": [
    "?BodyPostureEvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H17nrFCgdxZR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H17nrFCgdxZR",
    "outputId": "c154ca09-c9a5-4839-a6be-f63dd22cd209"
   },
   "outputs": [],
   "source": [
    "slice_dt = 2e6 # microseconds\n",
    "bin_dt = 2e3\n",
    "batch_size = 1\n",
    "\n",
    "raster_test_dataset = BodyPostureEvents(\n",
    "    data_path=dataset_path / \"data\" / \"test\",\n",
    "    cache_path=f\"cache/test/{slice_dt}/{bin_dt}\",\n",
    "    slice_dt=slice_dt,\n",
    "    bin_dt=bin_dt,\n",
    "    metadata_path=f\"metadata/raster/test/{slice_dt}/{bin_dt}\",\n",
    "    hot_pixel_filter_freq=hot_pixel_filter_freq,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(raster_test_dataset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1idK4ekvE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6f33fec98c324ee5967e8b7246f5629b",
      "cd289f24476941cf8554bed7ef748e85",
      "ecbe781d70964ad1afaaadde258c3933",
      "faf60190e5ff4589ab866bd8f30d2fd2",
      "5716e30646854bdb9b17829db907c2ca",
      "a278c9672fbd4b5cb1abc55691a6bf6a",
      "a47f41e8d15c466ba7875a121fa1b5b8",
      "f5d569e027da46ccb843a095617ede64",
      "93b214d34a6b47038a0f45c72231a360",
      "343beb7fe15b42b8a6a41186469a2ddc",
      "dac54eb3d336433a984f025573b21cd3"
     ]
    },
    "id": "2da1idK4ekvE",
    "outputId": "ffe20bc2-abd0-4c4d-a750-7bad02be7fea"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "snn.eval()\n",
    "snn = snn.to(device)\n",
    "\n",
    "val_data = []\n",
    "batch_loss = []\n",
    "for data, labels in tqdm(test_loader):\n",
    "  with torch.no_grad():\n",
    "    snn.reset_states()\n",
    "    data = data.to(device)\n",
    "    data = data.flatten(0, 1).float()\n",
    "    spikes = snn(data).unflatten(0, (batch_size, -1))\n",
    "\n",
    "    # Collect outputs and labels\n",
    "    labels = labels.to(device)\n",
    "    predictions = spikes.sum(1).argmax(dim=1) \n",
    "    val_data.append(predictions.eq(labels.view_as(predictions)))\n",
    "    print(f\"Spike output: {spikes.sum(1).int().tolist()[0]}, label was {labels.item()}. Overall accuracy: {round((sum(val_data)/len(val_data)).item(), 3)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5193LM6bRAJT",
   "metadata": {
    "id": "5193LM6bRAJT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Copy of AMLD_train_full.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0313e95d3bff4fa0a5e85982602447f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dce0d5e6f6e54860bcf76cdc238ff998",
       "IPY_MODEL_9e5eef22260240f484ef2ddfe4c6b7be",
       "IPY_MODEL_20214c91cc2b40178a9bf0a9b15f176d"
      ],
      "layout": "IPY_MODEL_944187b000714836b04a3c2c48a6538d"
     }
    },
    "20214c91cc2b40178a9bf0a9b15f176d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_543f3cea0c0441dfbf2b488ec2fecf6b",
      "placeholder": "​",
      "style": "IPY_MODEL_b674dc3bce7246dcbb6aefd051a7613e",
      "value": " 10/10 [00:16&lt;00:00,  1.67s/it, train_loss=0.378, val_acc=0.885, val_loss=0.341]"
     }
    },
    "343beb7fe15b42b8a6a41186469a2ddc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "543f3cea0c0441dfbf2b488ec2fecf6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5716e30646854bdb9b17829db907c2ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f33fec98c324ee5967e8b7246f5629b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cd289f24476941cf8554bed7ef748e85",
       "IPY_MODEL_ecbe781d70964ad1afaaadde258c3933",
       "IPY_MODEL_faf60190e5ff4589ab866bd8f30d2fd2"
      ],
      "layout": "IPY_MODEL_5716e30646854bdb9b17829db907c2ca"
     }
    },
    "8f32be1d210b4025a2b3248bf2ba1438": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "93b214d34a6b47038a0f45c72231a360": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "944187b000714836b04a3c2c48a6538d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e5eef22260240f484ef2ddfe4c6b7be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1f09e7b1e0f41f3bce2d10ac56e59f0",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8f32be1d210b4025a2b3248bf2ba1438",
      "value": 10
     }
    },
    "a278c9672fbd4b5cb1abc55691a6bf6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a47f41e8d15c466ba7875a121fa1b5b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b1f09e7b1e0f41f3bce2d10ac56e59f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b674dc3bce7246dcbb6aefd051a7613e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd289f24476941cf8554bed7ef748e85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a278c9672fbd4b5cb1abc55691a6bf6a",
      "placeholder": "​",
      "style": "IPY_MODEL_a47f41e8d15c466ba7875a121fa1b5b8",
      "value": " 24%"
     }
    },
    "dac54eb3d336433a984f025573b21cd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dce0d5e6f6e54860bcf76cdc238ff998": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6402d7a361843d19954eb0f1edbbbdd",
      "placeholder": "​",
      "style": "IPY_MODEL_e8d60af9b26a46088e166fadf01a5b6b",
      "value": "Epochs: 100%"
     }
    },
    "e8d60af9b26a46088e166fadf01a5b6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ecbe781d70964ad1afaaadde258c3933": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5d569e027da46ccb843a095617ede64",
      "max": 263,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_93b214d34a6b47038a0f45c72231a360",
      "value": 63
     }
    },
    "f5d569e027da46ccb843a095617ede64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6402d7a361843d19954eb0f1edbbbdd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "faf60190e5ff4589ab866bd8f30d2fd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_343beb7fe15b42b8a6a41186469a2ddc",
      "placeholder": "​",
      "style": "IPY_MODEL_dac54eb3d336433a984f025573b21cd3",
      "value": " 63/263 [01:37&lt;04:52,  1.46s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
